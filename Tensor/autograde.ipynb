{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:02.964776Z","iopub.execute_input":"2025-02-07T08:08:02.965254Z","iopub.status.idle":"2025-02-07T08:08:02.970356Z","shell.execute_reply.started":"2025-02-07T08:08:02.965214Z","shell.execute_reply":"2025-02-07T08:08:02.969272Z"}},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":"**Definition of AutoGrade**","metadata":{}},{"cell_type":"markdown","source":"AutoGrad (short for \"Automatic Differentiation\") is a core feature in PyTorch that automatically calculates gradients (derivatives) for you. This is very useful in deep learning because we need gradients for backpropagation during training.","metadata":{}},{"cell_type":"code","source":"import torch \nx = torch.tensor(3.0, requires_grad = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:02.971598Z","iopub.execute_input":"2025-02-07T08:08:02.971942Z","iopub.status.idle":"2025-02-07T08:08:02.988588Z","shell.execute_reply.started":"2025-02-07T08:08:02.971903Z","shell.execute_reply":"2025-02-07T08:08:02.987595Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:02.990517Z","iopub.execute_input":"2025-02-07T08:08:02.990798Z","iopub.status.idle":"2025-02-07T08:08:03.005554Z","shell.execute_reply.started":"2025-02-07T08:08:02.990771Z","shell.execute_reply":"2025-02-07T08:08:03.004532Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"tensor(3., requires_grad=True)"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"y = x**2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.006829Z","iopub.execute_input":"2025-02-07T08:08:03.007149Z","iopub.status.idle":"2025-02-07T08:08:03.017363Z","shell.execute_reply.started":"2025-02-07T08:08:03.007108Z","shell.execute_reply":"2025-02-07T08:08:03.016508Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"print(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.018271Z","iopub.execute_input":"2025-02-07T08:08:03.018698Z","iopub.status.idle":"2025-02-07T08:08:03.034563Z","shell.execute_reply.started":"2025-02-07T08:08:03.018664Z","shell.execute_reply":"2025-02-07T08:08:03.033648Z"}},"outputs":[{"name":"stdout","text":"tensor(9., grad_fn=<PowBackward0>)\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"y.backward()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.035527Z","iopub.execute_input":"2025-02-07T08:08:03.035816Z","iopub.status.idle":"2025-02-07T08:08:03.048276Z","shell.execute_reply.started":"2025-02-07T08:08:03.035784Z","shell.execute_reply":"2025-02-07T08:08:03.047257Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"x.grad","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.049238Z","iopub.execute_input":"2025-02-07T08:08:03.049545Z","iopub.status.idle":"2025-02-07T08:08:03.064815Z","shell.execute_reply.started":"2025-02-07T08:08:03.049513Z","shell.execute_reply":"2025-02-07T08:08:03.063678Z"}},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"tensor(6.)"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"x = torch.tensor(3.0, requires_grad = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.067201Z","iopub.execute_input":"2025-02-07T08:08:03.067514Z","iopub.status.idle":"2025-02-07T08:08:03.078557Z","shell.execute_reply.started":"2025-02-07T08:08:03.067487Z","shell.execute_reply":"2025-02-07T08:08:03.077604Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.155449Z","iopub.execute_input":"2025-02-07T08:08:03.155786Z","iopub.status.idle":"2025-02-07T08:08:03.161984Z","shell.execute_reply.started":"2025-02-07T08:08:03.155755Z","shell.execute_reply":"2025-02-07T08:08:03.161075Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"tensor(3., requires_grad=True)"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"y = x**2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.163450Z","iopub.execute_input":"2025-02-07T08:08:03.163800Z","iopub.status.idle":"2025-02-07T08:08:03.175635Z","shell.execute_reply.started":"2025-02-07T08:08:03.163770Z","shell.execute_reply":"2025-02-07T08:08:03.174583Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"z = torch.sin(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.177871Z","iopub.execute_input":"2025-02-07T08:08:03.178267Z","iopub.status.idle":"2025-02-07T08:08:03.194202Z","shell.execute_reply.started":"2025-02-07T08:08:03.178232Z","shell.execute_reply":"2025-02-07T08:08:03.193258Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.195694Z","iopub.execute_input":"2025-02-07T08:08:03.195995Z","iopub.status.idle":"2025-02-07T08:08:03.211626Z","shell.execute_reply.started":"2025-02-07T08:08:03.195961Z","shell.execute_reply":"2025-02-07T08:08:03.210587Z"}},"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"tensor(9., grad_fn=<PowBackward0>)"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"z","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.212649Z","iopub.execute_input":"2025-02-07T08:08:03.213008Z","iopub.status.idle":"2025-02-07T08:08:03.226289Z","shell.execute_reply.started":"2025-02-07T08:08:03.212973Z","shell.execute_reply":"2025-02-07T08:08:03.225198Z"}},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"tensor(0.4121, grad_fn=<SinBackward0>)"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"z.backward()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.227324Z","iopub.execute_input":"2025-02-07T08:08:03.227633Z","iopub.status.idle":"2025-02-07T08:08:03.239354Z","shell.execute_reply.started":"2025-02-07T08:08:03.227603Z","shell.execute_reply":"2025-02-07T08:08:03.238442Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"x.grad","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.240328Z","iopub.execute_input":"2025-02-07T08:08:03.240745Z","iopub.status.idle":"2025-02-07T08:08:03.258063Z","shell.execute_reply.started":"2025-02-07T08:08:03.240709Z","shell.execute_reply":"2025-02-07T08:08:03.257018Z"}},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"tensor(-5.4668)"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"#torch calculate the derivative only for the leaf node x is the \n#leaf from where the graph is started\n# input tensor is leaf \n# output tensor is root\n# others are intermediate tensor \ny.grad","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.259151Z","iopub.execute_input":"2025-02-07T08:08:03.259556Z","iopub.status.idle":"2025-02-07T08:08:03.273034Z","shell.execute_reply.started":"2025-02-07T08:08:03.259519Z","shell.execute_reply":"2025-02-07T08:08:03.272006Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-89-6c8f79004ec8>:6: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n  y.grad\n","output_type":"stream"}],"execution_count":89},{"cell_type":"code","source":"def binary_cross_empty_loss(predection, target):\n    epsilon = 1e-8\n    predection = torch.clamp(predection, epsilon, 1-epsilon)\n    return -(target*torch.log(predection)+(1-target)*torch.log(1-predection))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.275812Z","iopub.execute_input":"2025-02-07T08:08:03.276090Z","iopub.status.idle":"2025-02-07T08:08:03.290226Z","shell.execute_reply.started":"2025-02-07T08:08:03.276066Z","shell.execute_reply":"2025-02-07T08:08:03.289283Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"x = torch.tensor(6.7)\ny= torch.tensor(0.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.291537Z","iopub.execute_input":"2025-02-07T08:08:03.291911Z","iopub.status.idle":"2025-02-07T08:08:03.306391Z","shell.execute_reply.started":"2025-02-07T08:08:03.291875Z","shell.execute_reply":"2025-02-07T08:08:03.305424Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"w = torch.tensor(1.0, requires_grad=True)\nb = torch.tensor(0.0, requires_grad = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.307428Z","iopub.execute_input":"2025-02-07T08:08:03.307779Z","iopub.status.idle":"2025-02-07T08:08:03.325290Z","shell.execute_reply.started":"2025-02-07T08:08:03.307742Z","shell.execute_reply":"2025-02-07T08:08:03.324258Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"w","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.326278Z","iopub.execute_input":"2025-02-07T08:08:03.326594Z","iopub.status.idle":"2025-02-07T08:08:03.344202Z","shell.execute_reply.started":"2025-02-07T08:08:03.326561Z","shell.execute_reply":"2025-02-07T08:08:03.342989Z"}},"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"tensor(1., requires_grad=True)"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.345205Z","iopub.execute_input":"2025-02-07T08:08:03.345558Z","iopub.status.idle":"2025-02-07T08:08:03.359898Z","shell.execute_reply.started":"2025-02-07T08:08:03.345531Z","shell.execute_reply":"2025-02-07T08:08:03.358839Z"}},"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"tensor(0., requires_grad=True)"},"metadata":{}}],"execution_count":94},{"cell_type":"code","source":"z = w*x+b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.360957Z","iopub.execute_input":"2025-02-07T08:08:03.361369Z","iopub.status.idle":"2025-02-07T08:08:03.373746Z","shell.execute_reply.started":"2025-02-07T08:08:03.361339Z","shell.execute_reply":"2025-02-07T08:08:03.372686Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"z","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.374801Z","iopub.execute_input":"2025-02-07T08:08:03.375090Z","iopub.status.idle":"2025-02-07T08:08:03.391368Z","shell.execute_reply.started":"2025-02-07T08:08:03.375056Z","shell.execute_reply":"2025-02-07T08:08:03.390254Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"tensor(6.7000, grad_fn=<AddBackward0>)"},"metadata":{}}],"execution_count":96},{"cell_type":"code","source":"y_pred= torch.sigmoid(z)\ny_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.393435Z","iopub.execute_input":"2025-02-07T08:08:03.393793Z","iopub.status.idle":"2025-02-07T08:08:03.407635Z","shell.execute_reply.started":"2025-02-07T08:08:03.393763Z","shell.execute_reply":"2025-02-07T08:08:03.406660Z"}},"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"tensor(0.9988, grad_fn=<SigmoidBackward0>)"},"metadata":{}}],"execution_count":97},{"cell_type":"code","source":"loss = binary_cross_empty_loss(y_pred, y)\nloss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.408735Z","iopub.execute_input":"2025-02-07T08:08:03.409007Z","iopub.status.idle":"2025-02-07T08:08:03.423191Z","shell.execute_reply.started":"2025-02-07T08:08:03.408983Z","shell.execute_reply":"2025-02-07T08:08:03.422262Z"}},"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"tensor(6.7012, grad_fn=<NegBackward0>)"},"metadata":{}}],"execution_count":98},{"cell_type":"code","source":"loss.backward()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.424047Z","iopub.execute_input":"2025-02-07T08:08:03.424335Z","iopub.status.idle":"2025-02-07T08:08:03.437108Z","shell.execute_reply.started":"2025-02-07T08:08:03.424310Z","shell.execute_reply":"2025-02-07T08:08:03.436096Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"print(w.grad)\nprint(b.grad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:08:03.438107Z","iopub.execute_input":"2025-02-07T08:08:03.438477Z","iopub.status.idle":"2025-02-07T08:08:03.454658Z","shell.execute_reply.started":"2025-02-07T08:08:03.438442Z","shell.execute_reply":"2025-02-07T08:08:03.453545Z"}},"outputs":[{"name":"stdout","text":"tensor(6.6918)\ntensor(0.9988)\n","output_type":"stream"}],"execution_count":100},{"cell_type":"code","source":"#grad for Multiple value \nx = torch.tensor([1.0, 2.0, 3.0], requires_grad = True)\nx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:16:18.030898Z","iopub.execute_input":"2025-02-07T08:16:18.031283Z","iopub.status.idle":"2025-02-07T08:16:18.038553Z","shell.execute_reply.started":"2025-02-07T08:16:18.031247Z","shell.execute_reply":"2025-02-07T08:16:18.037445Z"}},"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"tensor([1., 2., 3.], requires_grad=True)"},"metadata":{}}],"execution_count":102},{"cell_type":"code","source":"y = (x**2).mean()\ny","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:17:09.677415Z","iopub.execute_input":"2025-02-07T08:17:09.677908Z","iopub.status.idle":"2025-02-07T08:17:09.686876Z","shell.execute_reply.started":"2025-02-07T08:17:09.677874Z","shell.execute_reply":"2025-02-07T08:17:09.685932Z"}},"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"tensor(4.6667, grad_fn=<MeanBackward0>)"},"metadata":{}}],"execution_count":104},{"cell_type":"code","source":"y.backward()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:17:26.296064Z","iopub.execute_input":"2025-02-07T08:17:26.296457Z","iopub.status.idle":"2025-02-07T08:17:26.302303Z","shell.execute_reply.started":"2025-02-07T08:17:26.296427Z","shell.execute_reply":"2025-02-07T08:17:26.301264Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"x.grad","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:17:41.643726Z","iopub.execute_input":"2025-02-07T08:17:41.644078Z","iopub.status.idle":"2025-02-07T08:17:41.651350Z","shell.execute_reply.started":"2025-02-07T08:17:41.644039Z","shell.execute_reply":"2025-02-07T08:17:41.650360Z"}},"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"tensor([0.6667, 1.3333, 2.0000])"},"metadata":{}}],"execution_count":107},{"cell_type":"code","source":"#cleaning Gradient\nx = torch.tensor(2.0, requires_grad= True)\nx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:31:04.755994Z","iopub.execute_input":"2025-02-07T08:31:04.756375Z","iopub.status.idle":"2025-02-07T08:31:04.764226Z","shell.execute_reply.started":"2025-02-07T08:31:04.756346Z","shell.execute_reply":"2025-02-07T08:31:04.762764Z"}},"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"tensor(2., requires_grad=True)"},"metadata":{}}],"execution_count":108},{"cell_type":"code","source":"y = x**2\ny","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:32:38.448148Z","iopub.execute_input":"2025-02-07T08:32:38.448525Z","iopub.status.idle":"2025-02-07T08:32:38.455413Z","shell.execute_reply.started":"2025-02-07T08:32:38.448491Z","shell.execute_reply":"2025-02-07T08:32:38.454313Z"}},"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"tensor(4., grad_fn=<PowBackward0>)"},"metadata":{}}],"execution_count":116},{"cell_type":"code","source":"y.backward()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:32:43.043645Z","iopub.execute_input":"2025-02-07T08:32:43.043975Z","iopub.status.idle":"2025-02-07T08:32:43.059371Z","shell.execute_reply.started":"2025-02-07T08:32:43.043944Z","shell.execute_reply":"2025-02-07T08:32:43.057746Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-118-ab75bb780f4c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."],"ename":"RuntimeError","evalue":"Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.","output_type":"error"}],"execution_count":118},{"cell_type":"code","source":"x.grad","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:32:49.365910Z","iopub.execute_input":"2025-02-07T08:32:49.366327Z","iopub.status.idle":"2025-02-07T08:32:49.372905Z","shell.execute_reply.started":"2025-02-07T08:32:49.366296Z","shell.execute_reply":"2025-02-07T08:32:49.371884Z"}},"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"tensor(4.)"},"metadata":{}}],"execution_count":119},{"cell_type":"code","source":"x.grad.zero_()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:32:52.053680Z","iopub.execute_input":"2025-02-07T08:32:52.054023Z","iopub.status.idle":"2025-02-07T08:32:52.060515Z","shell.execute_reply.started":"2025-02-07T08:32:52.053990Z","shell.execute_reply":"2025-02-07T08:32:52.059652Z"}},"outputs":[{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"tensor(0.)"},"metadata":{}}],"execution_count":120},{"cell_type":"code","source":"#disable grad\nx.requires_grad_(False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:35:43.219848Z","iopub.execute_input":"2025-02-07T08:35:43.220155Z","iopub.status.idle":"2025-02-07T08:35:43.226886Z","shell.execute_reply.started":"2025-02-07T08:35:43.220129Z","shell.execute_reply":"2025-02-07T08:35:43.225843Z"}},"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"tensor(2.)"},"metadata":{}}],"execution_count":122},{"cell_type":"code","source":"x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:35:47.728474Z","iopub.execute_input":"2025-02-07T08:35:47.728790Z","iopub.status.idle":"2025-02-07T08:35:47.735499Z","shell.execute_reply.started":"2025-02-07T08:35:47.728762Z","shell.execute_reply":"2025-02-07T08:35:47.734600Z"}},"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"tensor(2.)"},"metadata":{}}],"execution_count":123},{"cell_type":"code","source":"x = torch.tensor(2.0, requires_grad=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:37:42.578437Z","iopub.execute_input":"2025-02-07T08:37:42.578761Z","iopub.status.idle":"2025-02-07T08:37:42.582797Z","shell.execute_reply.started":"2025-02-07T08:37:42.578732Z","shell.execute_reply":"2025-02-07T08:37:42.581830Z"}},"outputs":[],"execution_count":127},{"cell_type":"code","source":"#other option \n\nz= x.detach()\nz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:36:58.053514Z","iopub.execute_input":"2025-02-07T08:36:58.053841Z","iopub.status.idle":"2025-02-07T08:36:58.060827Z","shell.execute_reply.started":"2025-02-07T08:36:58.053817Z","shell.execute_reply":"2025-02-07T08:36:58.059689Z"}},"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"tensor(2.)"},"metadata":{}}],"execution_count":124},{"cell_type":"code","source":"x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:37:47.963889Z","iopub.execute_input":"2025-02-07T08:37:47.964247Z","iopub.status.idle":"2025-02-07T08:37:47.970598Z","shell.execute_reply.started":"2025-02-07T08:37:47.964217Z","shell.execute_reply":"2025-02-07T08:37:47.969742Z"}},"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"tensor(2., requires_grad=True)"},"metadata":{}}],"execution_count":128}]}